{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lYh7r1mTf4uo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "requests version: 2.32.5\n",
            "pandas version: 2.3.3\n",
            "dlt version: 1.21.0\n",
            "duckdb version: 1.4.4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import dlt\n",
        "from dlt.destinations import filesystem\n",
        "import duckdb\n",
        "\n",
        "print(\"requests version: \" + str(requests.__version__))\n",
        "print(\"pandas version: \" + str(pd.__version__))\n",
        "print(\"dlt version: \" + str(dlt.__version__))\n",
        "print(\"duckdb version: \" + str(duckdb.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to downloaded service account JSON\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"gcs.json\"\n",
        "\n",
        "# Project name\n",
        "PROJECT_ID = \"sandbox-486719\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# SCHEMAS\n",
        "# -------------------------------\n",
        "\n",
        "YELLOW_RENAME = {\n",
        "    \"VendorID\": \"vendor_id\",\n",
        "    \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
        "    \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
        "    \"passenger_count\": \"passenger_count\",\n",
        "    \"trip_distance\": \"trip_distance\",\n",
        "    \"RatecodeID\": \"rate_code\",\n",
        "    \"store_and_fwd_flag\": \"store_and_fwd_flag\",\n",
        "    \"payment_type\": \"payment_type\",\n",
        "    \"fare_amount\": \"fare_amount\",\n",
        "    \"extra\": \"extra\",\n",
        "    \"mta_tax\": \"mta_tax\",\n",
        "    \"tip_amount\": \"tip_amount\",\n",
        "    \"tolls_amount\": \"tolls_amount\",\n",
        "    \"improvement_surcharge\": \"imp_surcharge\",\n",
        "    \"airport_fee\": \"airport_fee\",\n",
        "    \"total_amount\": \"total_amount\",\n",
        "    \"PULocationID\": \"pickup_location_id\",\n",
        "    \"DOLocationID\": \"dropoff_location_id\"\n",
        "}\n",
        "\n",
        "GREEN_RENAME = {\n",
        "    \"VendorID\": \"vendor_id\",\n",
        "    \"lpep_pickup_datetime\": \"pickup_datetime\",\n",
        "    \"lpep_dropoff_datetime\": \"dropoff_datetime\",\n",
        "    \"store_and_fwd_flag\": \"store_and_fwd_flag\",\n",
        "    \"RatecodeID\": \"rate_code\",\n",
        "    \"passenger_count\": \"passenger_count\",\n",
        "    \"trip_distance\": \"trip_distance\",\n",
        "    \"fare_amount\": \"fare_amount\",\n",
        "    \"extra\": \"extra\",\n",
        "    \"mta_tax\": \"mta_tax\",\n",
        "    \"tip_amount\": \"tip_amount\",\n",
        "    \"tolls_amount\": \"tolls_amount\",\n",
        "    \"ehail_fee\": \"ehail_fee\",\n",
        "    \"airport_fee\": \"airport_fee\",\n",
        "    \"total_amount\": \"total_amount\",\n",
        "    \"payment_type\": \"payment_type\",\n",
        "    \"trip_type\": \"trip_type\",\n",
        "    \"improvement_surcharge\": \"imp_surcharge\",\n",
        "    \"PULocationID\": \"pickup_location_id\",\n",
        "    \"DOLocationID\": \"dropoff_location_id\"\n",
        "}\n",
        "\n",
        "# Full schema objects including dtypes, rename map, column order, datetime columns\n",
        "YELLOW_SCHEMA = {\n",
        "    \"dtypes\": {\n",
        "        \"vendor_id\": \"string\",\n",
        "        \"pickup_datetime\": \"datetime64[ns]\",\n",
        "        \"dropoff_datetime\": \"datetime64[ns]\",\n",
        "        \"passenger_count\": \"Int64\",\n",
        "        \"trip_distance\": \"float64\",\n",
        "        \"rate_code\": \"string\",\n",
        "        \"store_and_fwd_flag\": \"string\",\n",
        "        \"payment_type\": \"string\",\n",
        "        \"fare_amount\": \"float64\",\n",
        "        \"extra\": \"float64\",\n",
        "        \"mta_tax\": \"float64\",\n",
        "        \"tip_amount\": \"float64\",\n",
        "        \"tolls_amount\": \"float64\",\n",
        "        \"imp_surcharge\": \"float64\",\n",
        "        \"airport_fee\": \"float64\",\n",
        "        \"total_amount\": \"float64\",\n",
        "        \"pickup_location_id\": \"string\",\n",
        "        \"dropoff_location_id\": \"string\",\n",
        "        \"data_file_year\": \"Int64\",\n",
        "        \"data_file_month\": \"Int64\"\n",
        "    },\n",
        "    \"rename_map\": YELLOW_RENAME,\n",
        "    \"columns\": [\n",
        "        \"vendor_id\", \"pickup_datetime\", \"dropoff_datetime\", \"passenger_count\", \"trip_distance\",\n",
        "        \"rate_code\", \"store_and_fwd_flag\", \"payment_type\", \"fare_amount\", \"extra\", \"mta_tax\",\n",
        "        \"tip_amount\", \"tolls_amount\", \"imp_surcharge\", \"airport_fee\", \"total_amount\",\n",
        "        \"pickup_location_id\", \"dropoff_location_id\", \"data_file_year\", \"data_file_month\"\n",
        "    ],\n",
        "    \"datetime_cols\": [\"pickup_datetime\", \"dropoff_datetime\"]\n",
        "}\n",
        "\n",
        "GREEN_SCHEMA = {\n",
        "    \"dtypes\": {\n",
        "        \"vendor_id\": \"string\",\n",
        "        \"pickup_datetime\": \"datetime64[ns]\",\n",
        "        \"dropoff_datetime\": \"datetime64[ns]\",\n",
        "        \"store_and_fwd_flag\": \"string\",\n",
        "        \"rate_code\": \"string\",\n",
        "        \"passenger_count\": \"Int64\",\n",
        "        \"trip_distance\": \"float64\",\n",
        "        \"fare_amount\": \"float64\",\n",
        "        \"extra\": \"float64\",\n",
        "        \"mta_tax\": \"float64\",\n",
        "        \"tip_amount\": \"float64\",\n",
        "        \"tolls_amount\": \"float64\",\n",
        "        \"ehail_fee\": \"float64\",\n",
        "        \"airport_fee\": \"float64\",\n",
        "        \"total_amount\": \"float64\",\n",
        "        \"payment_type\": \"string\",\n",
        "        \"distance_between_service\": \"float64\",\n",
        "        \"time_between_service\": \"Int64\",\n",
        "        \"trip_type\": \"string\",\n",
        "        \"imp_surcharge\": \"float64\",\n",
        "        \"pickup_location_id\": \"string\",\n",
        "        \"dropoff_location_id\": \"string\",\n",
        "        \"data_file_year\": \"Int64\",\n",
        "        \"data_file_month\": \"Int64\"\n",
        "    },\n",
        "    \"rename_map\": GREEN_RENAME,\n",
        "    \"columns\": [\n",
        "        \"vendor_id\", \"pickup_datetime\", \"dropoff_datetime\", \"store_and_fwd_flag\", \"rate_code\",\n",
        "        \"passenger_count\", \"trip_distance\", \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\",\n",
        "        \"tolls_amount\", \"ehail_fee\", \"airport_fee\", \"total_amount\", \"payment_type\",\n",
        "        \"distance_between_service\", \"time_between_service\", \"trip_type\", \"imp_surcharge\",\n",
        "        \"pickup_location_id\", \"dropoff_location_id\", \"data_file_year\", \"data_file_month\"\n",
        "    ],\n",
        "    \"datetime_cols\": [\"pickup_datetime\", \"dropoff_datetime\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# HELPER FUNCTIONS\n",
        "# -------------------------------\n",
        "\n",
        "def generate_file_urls(data_type = \"yellow\", start_year = 2019, end_year = 2020):\n",
        "    urls = []\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        for month in range(1, 13):\n",
        "            month_str = f\"{month:02d}\"\n",
        "            file_name = f\"{data_type}_tripdata_{year}-{month_str}.csv.gz\"\n",
        "            url = f\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/{data_type}/{file_name}\"\n",
        "            urls.append((file_name, url))\n",
        "    return urls\n",
        "\n",
        "def apply_schema(df: pd.DataFrame, schema: dict, year: int, month: int) -> pd.DataFrame:\n",
        "    # Rename columns\n",
        "    df = df.rename(columns = schema[\"rename_map\"])\n",
        "\n",
        "    # Add missing columns\n",
        "    for col in schema[\"columns\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = pd.NA\n",
        "\n",
        "    # Add year/month\n",
        "    df[\"data_file_year\"] = year\n",
        "    df[\"data_file_month\"] = month\n",
        "\n",
        "    # Datetime conversion\n",
        "    for col in schema[\"datetime_cols\"]:\n",
        "        df[col] = pd.to_datetime(df[col], errors = \"coerce\")\n",
        "\n",
        "    # Numeric conversion\n",
        "    for col, dtype in schema[\"dtypes\"].items():\n",
        "        if col in schema[\"datetime_cols\"]:\n",
        "            continue\n",
        "        if \"float\" in dtype or \"int\" in dtype:\n",
        "            df[col] = pd.to_numeric(df[col], errors = \"coerce\")\n",
        "\n",
        "    # String conversion\n",
        "    for col, dtype in schema[\"dtypes\"].items():\n",
        "        if dtype == \"string\":\n",
        "            df[col] = df[col].astype(\"string\")\n",
        "\n",
        "    # Final dtype enforcement\n",
        "    df = df.astype(schema[\"dtypes\"])\n",
        "\n",
        "    # Reorder columns\n",
        "    df = df[schema[\"columns\"]]\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------------\n",
        "# DLT SOURCE\n",
        "# -------------------------------\n",
        "\n",
        "def make_taxi_source(data_type = \"yellow\"):\n",
        "    schema = YELLOW_SCHEMA if data_type == \"yellow\" else GREEN_SCHEMA\n",
        "\n",
        "    @dlt.source(name = f\"{data_type}_tripdata\")\n",
        "    def taxi_source():\n",
        "        dfs = []\n",
        "        for file_name, url in generate_file_urls(data_type):\n",
        "            print(f\"Downloading {file_name}...\")\n",
        "\n",
        "            # Extract year/month\n",
        "            year_month = file_name.split(\"_\")[-1].replace(\".csv.gz\",\"\")\n",
        "            year, month = map(int, year_month.split(\"-\"))\n",
        "\n",
        "            # Retry loop\n",
        "            for attempt in range(3):\n",
        "                try:\n",
        "                    response = requests.get(url)\n",
        "                    if response.status_code != 200:\n",
        "                        raise ValueError(f\"File not found (status {response.status_code})\")\n",
        "\n",
        "                    df = pd.read_csv(\n",
        "                        BytesIO(response.content),\n",
        "                        compression = \"gzip\",\n",
        "                        dtype = {\"store_and_fwd_flag\": \"string\"},\n",
        "                        low_memory = False\n",
        "                    )\n",
        "\n",
        "                    # Apply schema\n",
        "                    df = apply_schema(df, schema, year, month)\n",
        "\n",
        "                    dfs.append(df)\n",
        "                    break\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Attempt {attempt + 1} failed for {file_name}: {e}\")\n",
        "                    if attempt == 2:\n",
        "                        print(f\"Skipping {file_name} after 3 failed attempts.\")\n",
        "                    else:\n",
        "                        print(\"Retrying...\")\n",
        "                            # Yield as DLT resource\n",
        "\n",
        "        yield dlt.resource(dfs, name = f\"{data_type}_tripdata\")\n",
        "\n",
        "    return taxi_source"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/rob/Projects/GitHub/data-engineering-zoomcamp/.venv/lib/python3.12/site-packages/dlt/pipeline/__init__.py:135: Dlt04DeprecationWarning: The `full_refresh` argument to pipeline is deprecated and will be removed in a future version. Use `dev_mode=True` instead which will have the same effect. Deprecated in dlt 0.4.0 to be removed in 1.0.0.\n",
            "  full_refresh_argument_deprecated(\"pipeline\", full_refresh)\n"
          ]
        }
      ],
      "source": [
        "# -------------------------------\n",
        "# PIPELINE\n",
        "# -------------------------------\n",
        "\n",
        "pipeline = dlt.pipeline(\n",
        "    pipeline_name = \"taxi_data_pipeline\",\n",
        "    destination = \"bigquery\",\n",
        "    dataset_name = \"nytaxi\",\n",
        "    dev_mode = True\n",
        ")\n",
        "\n",
        "# Example: create source and run\n",
        "yellow_source = make_taxi_source(\"yellow\")\n",
        "green_source = make_taxi_source(\"green\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading yellow_tripdata_2019-01.csv.gz...\n",
            "Downloading yellow_tripdata_2019-02.csv.gz...\n",
            "Downloading yellow_tripdata_2019-03.csv.gz...\n",
            "Downloading yellow_tripdata_2019-04.csv.gz...\n",
            "Downloading yellow_tripdata_2019-05.csv.gz...\n",
            "Downloading yellow_tripdata_2019-06.csv.gz...\n",
            "Downloading yellow_tripdata_2019-07.csv.gz...\n",
            "Downloading yellow_tripdata_2019-08.csv.gz...\n",
            "Downloading yellow_tripdata_2019-09.csv.gz...\n",
            "Downloading yellow_tripdata_2019-10.csv.gz...\n",
            "Downloading yellow_tripdata_2019-11.csv.gz...\n",
            "Downloading yellow_tripdata_2019-12.csv.gz...\n",
            "Downloading yellow_tripdata_2020-01.csv.gz...\n",
            "Downloading yellow_tripdata_2020-02.csv.gz...\n",
            "Downloading yellow_tripdata_2020-03.csv.gz...\n",
            "Downloading yellow_tripdata_2020-04.csv.gz...\n",
            "Downloading yellow_tripdata_2020-05.csv.gz...\n",
            "Downloading yellow_tripdata_2020-06.csv.gz...\n",
            "Downloading yellow_tripdata_2020-07.csv.gz...\n",
            "Downloading yellow_tripdata_2020-08.csv.gz...\n",
            "Downloading yellow_tripdata_2020-09.csv.gz...\n",
            "Downloading yellow_tripdata_2020-10.csv.gz...\n",
            "Downloading yellow_tripdata_2020-11.csv.gz...\n",
            "Downloading yellow_tripdata_2020-12.csv.gz...\n",
            "\n",
            "Yellow taxi data load info:\n",
            "Pipeline taxi_data_pipeline load step completed in 40 minutes and 15.02 seconds\n",
            "1 load package(s) were loaded to destination bigquery and into dataset nytaxi_20260213103812\n",
            "The bigquery destination used None@sandbox-486719 location to store data\n",
            "Load package 1771022710.54849 is LOADED and contains no failed jobs\n"
          ]
        }
      ],
      "source": [
        "# Load yellow data\n",
        "yellow_info = pipeline.run(yellow_source())\n",
        "\n",
        "print(\"\\nYellow taxi data load info:\")\n",
        "print(yellow_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading green_tripdata_2019-01.csv.gz...\n",
            "Downloading green_tripdata_2019-02.csv.gz...\n",
            "Downloading green_tripdata_2019-03.csv.gz...\n",
            "Downloading green_tripdata_2019-04.csv.gz...\n",
            "Downloading green_tripdata_2019-05.csv.gz...\n",
            "Downloading green_tripdata_2019-06.csv.gz...\n",
            "Downloading green_tripdata_2019-07.csv.gz...\n",
            "Downloading green_tripdata_2019-08.csv.gz...\n",
            "Downloading green_tripdata_2019-09.csv.gz...\n",
            "Downloading green_tripdata_2019-10.csv.gz...\n",
            "Downloading green_tripdata_2019-11.csv.gz...\n",
            "Downloading green_tripdata_2019-12.csv.gz...\n",
            "Downloading green_tripdata_2020-01.csv.gz...\n",
            "Downloading green_tripdata_2020-02.csv.gz...\n",
            "Downloading green_tripdata_2020-03.csv.gz...\n",
            "Downloading green_tripdata_2020-04.csv.gz...\n",
            "Downloading green_tripdata_2020-05.csv.gz...\n",
            "Downloading green_tripdata_2020-06.csv.gz...\n",
            "Downloading green_tripdata_2020-07.csv.gz...\n",
            "Downloading green_tripdata_2020-08.csv.gz...\n",
            "Downloading green_tripdata_2020-09.csv.gz...\n",
            "Downloading green_tripdata_2020-10.csv.gz...\n",
            "Downloading green_tripdata_2020-11.csv.gz...\n",
            "Downloading green_tripdata_2020-12.csv.gz...\n",
            "Green taxi data load info:\n",
            "Pipeline taxi_data_pipeline load step completed in 1 minute and 26.65 seconds\n",
            "2 load package(s) were loaded to destination bigquery and into dataset nytaxi_20260213103812\n",
            "The bigquery destination used None@sandbox-486719 location to store data\n",
            "Load package 1771025219.770161 is LOADED and contains no failed jobs\n",
            "Load package 1771025222.397908 is LOADED and contains no failed jobs\n"
          ]
        }
      ],
      "source": [
        "# Load green data\n",
        "green_info = pipeline.run(green_source())\n",
        "\n",
        "print(\"Green taxi data load info:\")\n",
        "print(green_info)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
